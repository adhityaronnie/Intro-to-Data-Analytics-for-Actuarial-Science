{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c6e9b3",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment 1 – Data Cleaning & Preparation (Health Insurance Claims)\n",
    "\n",
    "**Course:** Data Analytics for Actuarial Science  \n",
    "**Week:** 3  \n",
    "**Dataset:** `health_insurance_claims.csv`  \n",
    "**Deliverables:**  \n",
    "- Completed notebook (`.ipynb`)  \n",
    "- Cleaned dataset (`health_insurance_claims_clean.csv`)  \n",
    "- 1–2 page PDF summary of steps & justifications  \n",
    "\n",
    "> **Objective:** Inspect, clean, and prepare an actuarial claims dataset for downstream modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b6f53e",
   "metadata": {},
   "source": [
    "## 1. Setup & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "possible_paths = [\n",
    "    'health_insurance_claims.csv',\n",
    "    '/mnt/data/health_insurance_claims.csv'\n",
    "]\n",
    "\n",
    "data_path = None\n",
    "for p in possible_paths:\n",
    "    if os.path.exists(p):\n",
    "        data_path = p\n",
    "        break\n",
    "\n",
    "if data_path is None:\n",
    "    raise FileNotFoundError(\"Could not find 'health_insurance_claims.csv'. Please place it next to this notebook or adjust the path.\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(f'Loaded shape: {df.shape}')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f895056",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Initial Inspection (10 pts)\n",
    "- Show dataset shape and first 10 rows  \n",
    "- Identify numeric vs categorical variables  \n",
    "- Summary statistics for numeric columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Shape:', df.shape)\n",
    "display(df.head(10))\n",
    "print('\\nInfo:')\n",
    "df.info()\n",
    "print('\\nDescribe (numeric):')\n",
    "df.describe()\n",
    "print('\\nColumn dtypes:')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d6403e",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Missing Values (20 pts)\n",
    "- Count missing values per column  \n",
    "- Impute:  \n",
    "  - `age` → median  \n",
    "  - `claim_amount` → (mean or median) *justify*  \n",
    "  - `diagnosis_code` → mode  \n",
    "- Show before/after missing summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_before = df.isna().sum()\n",
    "print('Missing before:\\n', missing_before)\n",
    "\n",
    "# Impute age with median\n",
    "if 'age' in df.columns:\n",
    "    df['age'] = df['age'].fillna(df['age'].median())\n",
    "\n",
    "# Impute claim_amount with your choice (mean or median) – default median here\n",
    "if 'claim_amount' in df.columns:\n",
    "    df['claim_amount'] = df['claim_amount'].fillna(df['claim_amount'].median())\n",
    "\n",
    "# Impute diagnosis_code with mode (most frequent)\n",
    "if 'diagnosis_code' in df.columns:\n",
    "    mode_val = df['diagnosis_code'].mode(dropna=True)\n",
    "    if len(mode_val) > 0:\n",
    "        df['diagnosis_code'] = df['diagnosis_code'].fillna(mode_val.iloc[0])\n",
    "\n",
    "missing_after = df.isna().sum()\n",
    "print('\\nMissing after:\\n', missing_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da8ebc0",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Duplicates & Data Integrity (15 pts)\n",
    "- Count duplicate `claim_id` (if present)  \n",
    "- Drop duplicates and verify uniqueness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ab0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'claim_id' in df.columns:\n",
    "    dup_count = df.duplicated(subset='claim_id').sum()\n",
    "    print('Duplicate claim_id rows:', dup_count)\n",
    "    df = df.drop_duplicates(subset='claim_id')\n",
    "    print('New shape after dropping dup claim_id:', df.shape)\n",
    "    assert df['claim_id'].is_unique, \"claim_id is not unique after drop_duplicates\"\n",
    "else:\n",
    "    print(\"Column 'claim_id' not found; skipping this step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74624bb7",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Outlier Detection & Treatment (25 pts)\n",
    "- Use IQR on `claim_amount`  \n",
    "- Decide to remove / cap (winsorize) / transform (e.g., log) *with justification*  \n",
    "- Show before/after histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60eb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot BEFORE\n",
    "if 'claim_amount' in df.columns:\n",
    "    plt.figure()\n",
    "    plt.hist(df['claim_amount'].dropna(), bins=30)\n",
    "    plt.title('Claim Amount – Before')\n",
    "    plt.xlabel('claim_amount'); plt.ylabel('count')\n",
    "    plt.show()\n",
    "\n",
    "    # IQR method\n",
    "    q1 = df['claim_amount'].quantile(0.25)\n",
    "    q3 = df['claim_amount'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5*iqr\n",
    "    upper = q3 + 1.5*iqr\n",
    "    print(f'IQR bounds: [{lower:.2f}, {upper:.2f}]')\n",
    "\n",
    "    # Example: capping (winsorization)\n",
    "    df['claim_amount_capped'] = df['claim_amount'].clip(lower, upper)\n",
    "\n",
    "    # Plot AFTER\n",
    "    plt.figure()\n",
    "    plt.hist(df['claim_amount_capped'].dropna(), bins=30)\n",
    "    plt.title('Claim Amount – After Capping')\n",
    "    plt.xlabel('claim_amount_capped'); plt.ylabel('count')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Column 'claim_amount' not found; skipping outlier section.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b19083",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Transformations (20 pts)\n",
    "- Encode categoricals: `gender`, `policy_type`, `payment_status`  \n",
    "- Normalize/standardize `claim_amount` (or `claim_amount_capped`)  \n",
    "- Explain why scaling may matter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "categoricals = [c for c in ['gender', 'policy_type', 'payment_status', 'diagnosis_code'] if c in df.columns]\n",
    "df_encoded = pd.get_dummies(df, columns=categoricals, drop_first=True)\n",
    "\n",
    "target_col = 'claim_amount_capped' if 'claim_amount_capped' in df_encoded.columns else 'claim_amount'\n",
    "if target_col in df_encoded.columns:\n",
    "    scaler = StandardScaler()\n",
    "    df_encoded[target_col + '_z'] = scaler.fit_transform(df_encoded[[target_col]])\n",
    "else:\n",
    "    print(\"No claim amount column available for scaling.\")\n",
    "\n",
    "print('Encoded columns added. New shape:', df_encoded.shape)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff05959",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Save Outputs & Brief Report (10 pts)\n",
    "- Save cleaned dataset as `health_insurance_claims_clean.csv`  \n",
    "- Write 1–2 pages summarizing: imputation choices, outlier handling, encoding, scaling, and any assumptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef799678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_path = 'health_insurance_claims_clean.csv'\n",
    "df_encoded.to_csv(clean_path, index=False)\n",
    "print(f'Saved cleaned dataset to: {clean_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2e275",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Notes & Justifications (write here for the PDF report)\n",
    "- **Missing values:**  \n",
    "- **Duplicates:**  \n",
    "- **Outliers:**  \n",
    "- **Transformations:**  \n",
    "- **Assumptions & limitations:**  \n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
